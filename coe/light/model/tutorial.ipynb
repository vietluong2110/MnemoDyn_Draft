{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bf5e4c",
   "metadata": {},
   "source": [
    "# MnemoDyn Foundation Inference Tutorial\n",
    "\n",
    "This notebook only covers foundation-model inference (no downstream training/classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0fce1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnib\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchcde\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcoe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlight\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LitORionModelOptimized\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchcde\n",
    "\n",
    "from coe.light.model.main import LitORionModelOptimized\n",
    "\n",
    "\n",
    "def extract_val_mae(name: str) -> float:\n",
    "    m = re.search(r\"val_mae=([-+eE0-9.]+)\", name)\n",
    "    if not m:\n",
    "        return float(\"inf\")\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except ValueError:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "def find_best_checkpoint(version_dir: Path) -> Path:\n",
    "    ckpt_dir = version_dir / \"checkpoints\"\n",
    "    ckpts = sorted(ckpt_dir.glob(\"*.ckpt\"))\n",
    "    if not ckpts:\n",
    "        raise FileNotFoundError(f\"No checkpoints found under: {ckpt_dir}\")\n",
    "    return min(ckpts, key=lambda p: extract_val_mae(p.name))\n",
    "\n",
    "\n",
    "def load_dtseries(file_path: Path, target_length: int, num_parcels: int) -> torch.Tensor:\n",
    "    arr = nib.load(str(file_path)).get_fdata().astype(np.float32)  # [T, D]\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D dtseries array, got shape {arr.shape}\")\n",
    "    if arr.shape[1] != num_parcels:\n",
    "        raise ValueError(f\"Expected D={num_parcels}, got D={arr.shape[1]}\")\n",
    "\n",
    "    # Repeat/trim to checkpoint sequence length.\n",
    "    reps = int(np.ceil(target_length / arr.shape[0]))\n",
    "    arr = np.tile(arr, (reps, 1))[:target_length]\n",
    "    return torch.from_numpy(arr).unsqueeze(0)  # [1, T, D]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configure paths ----\n",
    "version_dir = Path(\"/nas/vhluong/Result/Orion_450_ukbiobank/debug_GordonHCP/version_2\")\n",
    "dtseries_path = Path(\"sub-011_task-rest_space-MNI305_preproc.dtseries_Schaefer2018_400Parcels_7Networks_order_Tian_Subcortex_S3.dlabel_parcellated.dtseries.nii\")\n",
    "interpol = \"spline\"  # or \"linear\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt_path = find_best_checkpoint(version_dir)\n",
    "\n",
    "lit = LitORionModelOptimized.load_from_checkpoint(str(ckpt_path), map_location=device)\n",
    "lit.eval()\n",
    "foundation = lit.model.to(device)\n",
    "for p in foundation.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "seq_length = int(lit.hparams.seq_length)\n",
    "num_parcels = int(lit.hparams.D)\n",
    "duration = float(lit.hparams.duration)\n",
    "\n",
    "x = load_dtseries(dtseries_path, target_length=seq_length, num_parcels=num_parcels).to(device)\n",
    "\n",
    "if interpol == \"linear\":\n",
    "    coeffs = torchcde.linear_interpolation_coeffs(x)\n",
    "elif interpol == \"spline\":\n",
    "    coeffs = torchcde.hermite_cubic_coefficients_with_backward_differences(x)\n",
    "else:\n",
    "    raise ValueError(\"interpol must be 'linear' or 'spline'\")\n",
    "\n",
    "time_step = torch.from_numpy(np.arange(0, duration, duration / seq_length)).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    U = foundation(x, coeffs, time_step)\n",
    "\n",
    "print(f\"Checkpoint: {ckpt_path}\")\n",
    "print(f\"Input shape:  {tuple(x.shape)}\")\n",
    "print(f\"Output shape: {tuple(U.shape)}\")\n",
    "\n",
    "# quick visualization for parcel 0\n",
    "x_np = x[0, :, 0].detach().cpu().numpy()\n",
    "u_np = U[0, :, 0].detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_np, label=\"input (parcel 0)\", alpha=0.8)\n",
    "plt.plot(u_np, label=\"foundation output (parcel 0)\", alpha=0.8)\n",
    "plt.title(\"Foundation Inference: Input vs Output\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
